{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the problem\n",
    "The following scenario is purely fictional and is intended to interest people in the problem we are trying to solve.\n",
    "\n",
    "*Assume that you are running a website where people can post reviews of drinks such as wine, beer, and spirits (whiskey, gin etc). As an administrator of the website you want to keep things transparent and the reviews objective, so you only allow the reviewers to taste and review only one kind of drink, preferably focusing on wine since this is what the website is most famous for. However, you (the administrator) are growing suspicious that there are some reviewers who are cross drinking and posting reviews for other drinks. You want to stop this behaviour but you don't want to piss off your tasters because they are good at their job, so you hire a data scientist to build an ML model to identify tasters who are cross drinking and reviewing other drinks.*\n",
    "\n",
    "The domain we are working on is a corpus of wine and beer reviews collected from a website called [Wine Enthusiast](https://www.winemag.com/). The writers of our corpus are people who review and rate wines, beers and spirits professionally. Some of these tasters specialize on one drink (most of them in wine) and some others embrace cross drinking and delve into other beverage categories.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem methodology\n",
    "This notebook will focus on building a machine learning model, trained on wine and spirits reviews, to recognize tasters who are cross drinking and reviewing other beverages. The model will be evaluated against a collection of beer reviews where it will try to identify tasters based on their unique style.\n",
    "\n",
    "Based on some thorough inspection of the data, we saw that there are 19 wine tasters, 2 beer tasters and 1 spirits taster. The 2 beer tasters also review wines, so they would be the people we would like to identify. The problem, then, boils down to a binary classification problem. We will use the wine dataset and the spirits dataset and we will train a model to identify two categories, **wine_taster** and **spirits_taster**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "Goal of this project:\n",
    "    1. train a machine learning model on wine and spirits reviews\n",
    "    2. use the model on a completely new dataset from beer reviews to identify tasters who have reviewed wines\n",
    "    3. build an understanding of the features that considered to be important for this task\n",
    "    4. we must know the goodness of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Notebook details\n",
    "* Datasets source: We will be using three different datasets that have been collected from the [same website](https://www.winemag.com/) but have been acquired differently. The wine reviews dataset was downloaded from [Kaggle](https://www.kaggle.com/zynicide/wine-reviews) thanks to the user zackthoutt who did all the hard work to scrape the data. The beer and spirits reviews dataset was downloaded using Zack's scrape which can be found on his [github page](https://github.com/zackthoutt/wine-deep-learning).\n",
    "* Metadata: Because the data have been collected the same way, their metadata are similar.\n",
    "    - country: The country that the wine is from, String\n",
    "    - description: A few sentences from a sommelier describing the wine's taste, smell, look, feel. String\n",
    "    * designation: The vineyard within the winery where the grapes that made the wine are from, String\n",
    "    * points: The number of points WineEnthusiast rated the wine on a scale of 1-100 (though they say they only post reviews for wines that score >=80), Numeric\n",
    "    * price: The cost for a bottle of the wine, Numeric\n",
    "    * province: The province or state that the wine is from, String\n",
    "    * region_1: Tthe wine growing area in a province or state (ie Napa), String\n",
    "    * region_2: Sometimes there are more specific regions specified within a wine growing area (ie Rutherford inside the Napa Valley), but this value can sometimes be blank, String\n",
    "    * variety: The type of grapes used to make the wine (ie Pinot Noir), String\n",
    "    * winery: The winery that made the wine, String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasileios.vyzas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\vasileios.vyzas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, f_classif\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "nlp = spacy.load('en')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C://Users/vasileios.vyzas/Documents/workspace/Projects/Miscellaneous/wine_critic_recognizer/')\n",
    "# os.chdir('/home/fykos/Documents/workspace/wine_critic_recognizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spirits = pd.read_json('data/raw/spirits.json')\n",
    "wine = pd.read_csv('data/raw/winemag-data-130k-v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing and cleaning\n",
    "Given that the drinks we are working with are very different, features such as country, points, price, province etc. are not useful. Therefore, we are only interested in the description column which later will give us enough information to identify reviewers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop all unnecessary columns from both datasets\n",
    "wine = wine.drop(['Unnamed: 0', 'country', 'points', 'price', 'province', 'title', 'designation', 'region_1', 'region_2', 'taster_twitter_handle', 'variety', 'winery'], axis = 1)\n",
    "spirits = spirits.drop(['country', 'points', 'price', 'province', 'title', 'designation', 'region_1', 'region_2', 'taster_twitter_handle', 'variety', 'winery'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the wine dataset has more than 100000 rows, and using all of them for the classification\n",
    "# will create an imbalanced classification problem.\n",
    "wine_less_rows = wine.copy()\n",
    "wine_less_rows = wine_less_rows[:5000]\n",
    "wine_less_rows['label'] = 'wine_taster'\n",
    "spirits['label'] = 'spirits_taster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine wines and spirits\n",
    "all_drinks = pd.concat([wine_less_rows, spirits])\n",
    "all_drinks.reset_index(inplace=True)\n",
    "all_drinks.drop(['taster_name', 'index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spirits_taster</th>\n",
       "      <td>4422</td>\n",
       "      <td>4369</td>\n",
       "      <td>The muted bouquet is slow in offering woody, l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine_taster</th>\n",
       "      <td>5000</td>\n",
       "      <td>4985</td>\n",
       "      <td>There's a touch of toasted almond at the start...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               description         \\\n",
       "                     count unique   \n",
       "label                               \n",
       "spirits_taster        4422   4369   \n",
       "wine_taster           5000   4985   \n",
       "\n",
       "                                                                        \n",
       "                                                              top freq  \n",
       "label                                                                   \n",
       "spirits_taster  The muted bouquet is slow in offering woody, l...    2  \n",
       "wine_taster     There's a touch of toasted almond at the start...    2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_drinks.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There seem to be some duplicates records in the dataset. Let's remove them\n",
    "all_drinks.drop_duplicates(subset='description', keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spirits_taster</th>\n",
       "      <td>4369</td>\n",
       "      <td>4369</td>\n",
       "      <td>The mild aroma hints at vanilla and stone frui...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine_taster</th>\n",
       "      <td>4985</td>\n",
       "      <td>4985</td>\n",
       "      <td>The 18 months of aging in 90% American oak rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               description         \\\n",
       "                     count unique   \n",
       "label                               \n",
       "spirits_taster        4369   4369   \n",
       "wine_taster           4985   4985   \n",
       "\n",
       "                                                                        \n",
       "                                                              top freq  \n",
       "label                                                                   \n",
       "spirits_taster  The mild aroma hints at vanilla and stone frui...    1  \n",
       "wine_taster     The 18 months of aging in 90% American oak rea...    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking again the unique number of records\n",
    "all_drinks.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature engineering\n",
    "As we mentioned the description column which is text data will not give us any useful information to recognize authors of wine and spirits reviews. However, we can use the individual descriptions to create features that represent the writing style and linguistic patterns the authors follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(review):\n",
    "    review_letters = re.sub('[^a-zA-Z]', ' ', str(review))\n",
    "    review_letters = review_letters.lower()\n",
    "    return (\" \".join(review_letters.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(review):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    ls = [word for word in review.split() if word not in stop_words]\n",
    "    return (\" \".join(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemming(review):\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = [stemmer.stem(word) for word in review.split()]\n",
    "    return (\" \".join(stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_reviews = []\n",
    "reviews = all_drinks['description']\n",
    "for review in reviews:\n",
    "    processed_reviews.append(remove_stopwords(normalize(review)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', min_df=5, max_df = 0.95, ngram_range=(1,2))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features holds a list of all the words in the tfidf's vocabulary in the same order as the column in the matrix\n",
    "features = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = np.asarray(tfidf_matrix.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term':features, 'weights':weights})\n",
    "weights_df = weights_df.sort_values(by='weights', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_terms = weights_df['term'][:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_of_important_words(review):\n",
    "    count = 0\n",
    "    for word in normalize(review).split():\n",
    "        if word in important_terms:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks['count_of_important_words'] = all_drinks['description'].map(count_of_important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    letters = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    words = letters.lower().strip()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count number of words used in a review\n",
    "# normalize a review to remove punctuation in order to count accurately\n",
    "all_drinks['description_length'] = all_drinks['description'].apply(lambda text: len(str(normalize(text)).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# total count of all words and punctuation used in a description\n",
    "all_drinks['count_of_characters'] = all_drinks['description'].apply(lambda text: len(str(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks['average_length_of_words'] = all_drinks['count_of_characters'] / all_drinks['description_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punctuation_counter(review):\n",
    "    count = 0\n",
    "    doc = nlp(review)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_punct:\n",
    "            count+=1\n",
    "    return count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count of punctuation symbols used\n",
    "all_drinks['number_of_punctuation'] = all_drinks['description'].map(punctuation_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to find and count the number of nouns in a wine review\n",
    "def noun_getter(review):\n",
    "    count = 0\n",
    "    doc = nlp(review)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ == 'NOUN':\n",
    "            count+=1\n",
    "    return count        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks['number_of_nouns'] = all_drinks['description'].map(noun_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to find and count the number of noun phrases used in a review\n",
    "def noun_chunks_getter(review):\n",
    "    count = 0\n",
    "    doc = nlp(str(review))\n",
    "    \n",
    "    for token in doc.noun_chunks:\n",
    "        if len(str(token.text).split()) > 1:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks['number_of_noun_phrases'] = all_drinks['description'].map(noun_chunks_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to find and count the number of verbs in a wine review\n",
    "def verb_getter(review):\n",
    "    count = 0\n",
    "    doc = nlp(review)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB':\n",
    "            count+=1\n",
    "    return count        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks['number_of_verbs'] = all_drinks['description'].map(verb_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to find and count the number of adjective in a wine review\n",
    "def adj_getter(review):\n",
    "    count = 0\n",
    "    doc = nlp(review)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ == 'ADJ':\n",
    "            count+=1\n",
    "    return count        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks['number_of_adj'] = all_drinks['description'].map(adj_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_sentences(review):\n",
    "    doc = nlp(review)\n",
    "    return (len([sentence for sentence in doc.sents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks['count_of_sentences'] = all_drinks['description'].map(count_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_sentence_length_with_pos_tags(review):\n",
    "    doc = nlp(review)\n",
    "    pos_tags_dict = dict()\n",
    "    for sentence in doc.sents:\n",
    "        doc1 = nlp(str(sentence)) \n",
    "        pos_tags_dict[len(doc1)] = (noun_getter(str(sentence)), verb_getter(str(sentence)), adj_getter(str(sentence)))\n",
    "    return pos_tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length_list = []\n",
    "min_length_list = []\n",
    "nouns_list = []\n",
    "verb_list = []\n",
    "adj_list = []\n",
    "\n",
    "for review in all_drinks['description']:\n",
    "    d = find_sentence_length_with_pos_tags(review)\n",
    "    max_length = ((max(k for k, v in d.items())))\n",
    "    min_length_list.append((min(k for k, v in d.items())))\n",
    "    noun_count, verb_count, adj_count = d[max_length]\n",
    "    \n",
    "    max_length_list.append(max_length)\n",
    "    nouns_list.append(noun_count)\n",
    "    verb_list.append(verb_count)\n",
    "    adj_list.append(adj_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks['number_of_characters_in_largest_sentence'] = max_length_list\n",
    "all_drinks['number_of_characters_in_smallest_sentence'] = min_length_list\n",
    "all_drinks['number_of_nouns_in_largest_sentence'] = nouns_list\n",
    "all_drinks['number_of_verbs_in_largest_sentence'] = verb_list\n",
    "all_drinks['number_of_adjectives_in_largest_sentence'] = adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "all_drinks['count_of_stopwords'] = all_drinks['description'].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks['count_title_case_words'] = all_drinks['description'].apply(lambda x: len([w for w in str(x).replace('I','i').replace('A','a').split() if w.istitle() == True]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# definition of function found here: https://medium.com/@dimitrisspathis/exploring-linguistic-patterns-in-best-selling-book-series-100290c94242\n",
    "def automated_readability_index(characters, words, sentences):\n",
    "    ati = 4.71 * (characters/words) + 0.5 * (words/sentences) - 21.43\n",
    "    return ati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks['automated_readability_index'] = all_drinks.apply(lambda x: automated_readability_index(x['count_of_characters'], x['description_length'], x['count_of_sentences']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to find and count the number of adjective in a wine review\n",
    "def adv_getter(review):\n",
    "    count = 0\n",
    "    doc = nlp(review)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ == 'ADV':\n",
    "            count+=1\n",
    "    return count        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks['count_of_adverbs'] = all_drinks['description'].map(adv_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexical_density(nouns, verbs, adjectives, adverbs, words):\n",
    "    ld = ((nouns + verbs + adjectives + adverbs) / words) * 100\n",
    "    return ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks['lexical_density'] = all_drinks.apply(lambda x: lexical_density(x['number_of_nouns'], x['number_of_verbs'], x['number_of_adj'], x['count_of_adverbs'], x['description_length']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature engineering operations take to long to complete\n",
    "# saving the dataframe to save time in future reads\n",
    "all_drinks.to_csv('data/modified/wine_and_spirits_reviews_with_generated_features.csv', encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data exploration & visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_drinks = pd.read_csv('data/modified/wine_and_spirits_reviews_with_generated_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drinks.hist(column='description_length', by='label', bins=50, figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drinks.groupby('label')['description_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drinks.hist(column='number_of_punctuation', by='label', bins=20, figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drinks.hist(column='number_of_nouns', by='label', bins=30, figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model building & evaluation\n",
    "Below we are splitting the dataset into training and test set, 80% of the observations will go to the training and 20% will go to the testing. Techinically, the test dataset could be called a validation set because the real test dataset, as I mentioned before, is the beer reviews dataset. This dataset will be used last and it will have no involvement in the training phase, it's practically a new, unseen dataset.\n",
    "\n",
    "The main goal in this part is to test various learning algorithms and build a model that generalizes well. For the model building phase we are using GridSearchCV to find the most optimal parameters for the estimator. Additionally, GridSearchCV is optimized by cross validation, which can give us a good idea of how well the model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drinks = pd.read_csv('data/modified/wine_and_spirits_reviews_with_generated_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# will drop the description feature because I don't need it anymore\n",
    "drinks = drinks.drop(['description'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drinks['label'] = drinks['label'].map({'wine_taster': 1, 'spirits_taster': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = drinks.loc[:, drinks.columns != 'label'], drinks.loc[:,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting the dataset into 80% for the training and 20% for the test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Cross validation experiments\n",
    "For this part, three algorithms were tested, a Logistic Regression classifier, a Random Forest classifiers and a Support Vector Machine classifier. The range of parameters used in GridSearchCV were found by trial and error and a lot of research online.\n",
    "\n",
    "For the best parameters for Logistic Regression model this [kaggle notebook](https://www.kaggle.com/joparga3/2-tuning-parameters-for-logistic-regression/code) was found. For the Random Forest parameters, also a [kaggle notebook](https://www.kaggle.com/hadend/tuning-random-forest-parameters) was consulted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note to self: SelectKBest selects the top k features that have maximum relevance with the target variable. It takes two parameters as input arguments, \"k\" (obviously) and the score function to rate the relevance of every feature with the target variable. For example, for a regression problem, you can supply \"feature_selection.f_regression\" and for a classification problem, you can supply \"feature_selection.f_classif\".*\n",
    "\n",
    "*You can use SelectKBest and GridSearchCV together using a Pipeline with an estimator as the second step. The pipeline applies the first step by choosing the best k features and transforms the input data to have only these features. After transformation, this is then fit with your estimator. The GridSearchCV helps you to tune the \"number of features to be selected\" and the hyperparameter of the estimator, by selecting the parameters that give the best score on validation data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(f_classif)\n",
    "stdScaler = StandardScaler()\n",
    "pipeline = Pipeline([('stdScaler', stdScaler), ('kbest', kbest), ('lr', LogisticRegression())])\n",
    "grid_search = GridSearchCV(pipeline, {'kbest__k': [1,2,3,4,5, 6,7,8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'lr__C': [0.001,0.01,0.1,1,10,100,1000]}, cv = 5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid_search.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(f_classif)\n",
    "stdScaler = StandardScaler()\n",
    "pipeline = Pipeline([('stdScaler', stdScaler), ('kbest', kbest), ('clf', RandomForestClassifier())])\n",
    "grid_search = GridSearchCV(pipeline, {'kbest__k': [1,2,3,4,5, 6,7,8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'clf__n_estimators': [5, 40, 42, 100], \"clf__max_depth\": [5, 6],\n",
    "              \"clf__min_samples_split\": [5, 10],\n",
    "              \"clf__min_samples_leaf\": [3, 5],\n",
    "              \"clf__max_leaf_nodes\": [14, 15]}, cv = 5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid_search.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(f_classif)\n",
    "stdScaler = StandardScaler()\n",
    "pipeline = Pipeline([('kbest', kbest), ('stdScaler', stdScaler), ('clf', svm.SVC(kernel='linear'))])\n",
    "grid_search = GridSearchCV(pipeline, {'kbest__k': [1,2,3,4,5, 6,7,8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'clf__C': [0.001, 0.01, 0.1, 1, 10], \"clf__gamma\": [0.001, 0.01, 0.1, 1]}, cv=5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid_search.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Testing the most optimal parameters found for the SVM model with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is no particular reason in the choice of algorithms, just curiosity of performance\n",
    "kbest = SelectKBest(f_classif, k=20)\n",
    "stdScaler = StandardScaler()\n",
    "pipeline = Pipeline([('kbest', kbest), ('stdScaler', stdScaler), ('clf', svm.SVC(kernel='linear', C = 10, gamma = 0.001))])\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_prediction = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVM accuracy', accuracy_score(y_test, svm_prediction))\n",
    "print ('SVM confusion matrix\\n', confusion_matrix(y_test, svm_prediction))\n",
    "print ('(row=expected, col=predicted)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, logreg_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output of the confusion matrix, it seems that the SVM model is working descently well. It has managed to predict correctly 834 reviewers out of 1004 are wine reviewers and 574 out of 867 are spirits reviewers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Moment of Truth: Testing the model with beer reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beer = pd.read_json('data/raw/beers.json')\n",
    "beer = beer.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_reviews = []\n",
    "reviews = beer['description']\n",
    "for review in reviews:\n",
    "    processed_reviews.append(remove_stopwords(normalize(review)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', min_df=5, max_df = 0.95, ngram_range=(1,2))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features holds a list of all the words in the tfidf's vocabulary in the same order as the column in the matrix\n",
    "features = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = np.asarray(tfidf_matrix.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term':features, 'weights':weights})\n",
    "weights_df = weights_df.sort_values(by='weights', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_terms = weights_df['term'][:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_of_important_words(review):\n",
    "    count = 0\n",
    "    for word in normalize(review).split():\n",
    "        if word in important_terms:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beer['count_of_important_words'] = beer['description'].map(count_of_important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beer['count_of_adverbs'] = beer['description'].map(adv_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beer['count_of_important_words'] = beer['description'].map(count_of_important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beer['description_length'] = beer['description'].apply(lambda text: len(str(text).split()))\n",
    "\n",
    "beer['count_of_characters'] = beer['description'].apply(lambda text: len(text))\n",
    "\n",
    "beer['average_length_of_words'] = beer['count_of_characters'] / beer['description_length']\n",
    "\n",
    "beer['number_of_punctuation'] = beer['description'].map(punctuation_counter)\n",
    "\n",
    "beer['number_of_nouns'] = beer['description'].map(noun_getter)\n",
    "\n",
    "beer['number_of_noun_phrases'] = beer['description'].map(noun_chunks_getter)\n",
    "\n",
    "beer['number_of_verbs'] = beer['description'].map(verb_getter)\n",
    "\n",
    "beer['number_of_adj'] = beer['description'].map(adj_getter)\n",
    "\n",
    "beer['count_of_sentences'] = beer['description'].map(count_sentences)\n",
    "\n",
    "max_length_list = []\n",
    "min_length_list = []\n",
    "nouns_list = []\n",
    "verb_list = []\n",
    "adj_list = []\n",
    "\n",
    "for review in beer['description']:\n",
    "    d = find_sentence_length_with_pos_tags(review)\n",
    "    max_length = ((max(k for k, v in d.items())))\n",
    "    min_length_list.append((min(k for k, v in d.items())))\n",
    "    noun_count, verb_count, adj_count = d[max_length]\n",
    "    \n",
    "    max_length_list.append(max_length)\n",
    "    nouns_list.append(noun_count)\n",
    "    verb_list.append(verb_count)\n",
    "    adj_list.append(adj_count)\n",
    "\n",
    "beer['number_of_characters_in_largest_sentence'] = max_length_list\n",
    "beer['number_of_characters_in_smallest_sentence'] = min_length_list\n",
    "beer['number_of_nouns_in_largest_sentence'] = nouns_list\n",
    "beer['number_of_verbs_in_largest_sentence'] = verb_list\n",
    "beer['number_of_adjectives_in_largest_sentence'] = adj_list\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "beer['count_of_stopwords'] = beer['description'].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]) )\n",
    "\n",
    "beer['count_of_upper_case_words'] = beer['description'].apply(lambda x: len([w for w in str(x).replace('I','i').replace('A','a').split() if w.isupper() == True]) )\n",
    "\n",
    "beer['count_title_case_words'] = beer['description'].apply(lambda x: len([w for w in str(x).replace('I','i').replace('A','a').split() if w.istitle() == True]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beer['lexical_density'] = beer.apply(lambda x: lexical_density(x['number_of_nouns'], x['number_of_verbs'], x['number_of_adj'], x['count_of_adverbs'], x['description_length']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beer['automated_readability_index'] = beer.apply(lambda x: automated_readability_index(x['count_of_characters'], x['description_length'], x['count_of_sentences']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beer.drop(['description'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beer.drop(['country', 'designation', 'points', 'price', 'province', 'region_1', 'region_2', 'taster_twitter_handle', 'title', 'variety', 'winery'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beer.drop('taster_name', axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(beer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.bincount(predictions)\n",
    "ii = np.nonzero(y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(ii,y[ii]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the classifier found all the reviews in the beer dataset to belong to class 1 which is the wine_taster class. As we mentioned in the introduction, the beer reviews have been done by two reviewers who also double on wine reviews as well. Surprisingly, the SVM model was able to find correctly all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lessons learned and goals achieved\n",
    "Following are some observations and things I learned while doing this exercise:\n",
    "\n",
    "1. We managed to successfully train an SVM model to recognize wine reviewers.\n",
    "    \n",
    "    - Feature engineering played a key role to this task. With more research we can probably generate more and better features.\n",
    "    - Cross validation and parameter estimation with GridSearchCV were very useful but extremely time consuming. Logistic Regression had the fastest training time, taking about 3-4 minutes. Random Forest took about 12-15 minutes and SVM took about 35 minutes.\n",
    "2. We successfully used the model on a completely new dataset from beer reviews. The model performed really well by classifying all the reviews in the dataset as a wine_taster class, meaning that all the reviews have been written by wine reviewers.\n",
    "3. The SVM model has achieved an accuracy score of 75%. Initially, with about 10 features and a normal train-test split approach we had achieved a score of 70%. By introducing more important features and performing parameter tuning in combination with cross validation we managed to increase the accuracy at 75%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
